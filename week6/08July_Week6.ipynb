{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "eeab229e",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 13px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\">\n",
                "This notebook documents my theoretical study alongside the lab exercises conducted on <b>July 8 & 9, 2025</b>.\n",
                "</h5>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8f662707",
            "metadata": {},
            "source": [
                "### <u><b>LAB EXERCISES:</b></u> **WEEK 6**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f3c26888",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 12px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em;\">\n",
                "    <b style=\"font-size: 16px;\">Overview:</b> Build a RAG pipeline to collect, clean, and balance product data, then standardize this data into <code>Item</code> objects with well-structured prompts and token counts suitable for training a product pricing model. Also, tokenizer behavior is validated to ensure that 3-digit price values were encoded into a single token, preparing the dataset for upcoming training and evaluation steps.\n",
                "  </h5>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "29c2e502",
            "metadata": {},
            "source": [
                "#### <code>**day1.ipynb**</code>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "111e31d0",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b style=\"font-size: 16px;\">Abstract:</b> Begin the <b>Product Pricer</b> project by curating a dataset of <b>Home Appliances</b> from Amazon reviews. Focus on items with prices and prepare them for training by creating <code>Item</code> objects with truncated text and prompts.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8dce24f1",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h4 style=\"margin-bottom: 0.3em; font-size: 16px;\"><b>The Big Project Begins!</b></h4>\n",
                "  <b>Product Pricer:</b> A model that can estimate how much something costs based on its description.<br>\n",
                "  <b>Data Curation – Part 1:</b> We’ll begin curating and cleaning a subset of the dataset, focusing on <b>Home Appliances</b>.<br>\n",
                "  <b>Dataset source:</b><br>\n",
                "  <a href=\"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\" target=\"_blank\">https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023</a><br>\n",
                "  <b>Meta categories folder:</b><br>\n",
                "  <a href=\"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories\" target=\"_blank\">https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories</a>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a134d527",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 15px;\"><b>Sidenote: What is Data Curation?</b></h5>\n",
                "  Data curation is the process of collecting, cleaning, organizing, and preparing raw data into a high-quality, structured dataset suitable for analysis or machine learning tasks.<br>\n",
                "  In the context of this week, curation includes:\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em;\">\n",
                "    <li>Selecting relevant data points (e.g., products with valid prices)</li>\n",
                "    <li>Removing or correcting errors, inconsistencies, or irrelevant entries</li>\n",
                "    <li>Balancing the dataset by category or price range</li>\n",
                "    <li>Formatting data: creating prompts, truncating text, tokenizing</li>\n",
                "    <li>Saving curated outputs for reuse in training and evaluation</li>\n",
                "  </ul>\n",
                "  Well-curated data ensures your models are trained on accurate, representative, and relevant samples — leading to stronger performance and more trustworthy results.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e27333d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Anaconda (conda) users:\n",
                "# conda install -c conda-forge datasets matplotlib matplotlib-inline scipy<1.13 gensim anthropic ollama\n",
                "\n",
                "# Python (pip) users:\n",
                "# pip install datasets matplotlib matplotlib-inline scipy<1.13 gensim anthropic ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4ec654ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from huggingface_hub import login\n",
                "from datasets import load_dataset, Dataset, DatasetDict\n",
                "import matplotlib.pyplot as plt\n",
                "from items import Item"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5b2ecc74",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv(override=True)\n",
                "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9d9bd3c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "hf_token = os.environ['HF_TOKEN']\n",
                "login(hf_token, add_to_git_credential=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19c4d0b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# %matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c68c5f73",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load in our dataset\n",
                "\n",
                "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_meta_Appliances\", split=\"full\", trust_remote_code=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "36140541",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Number of Appliances: {len(dataset):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "610fd26e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Investigate a particular datapoint\n",
                "datapoint = dataset[2]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b67a5cec",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Investigate\n",
                "print(datapoint[\"title\"])\n",
                "print(datapoint[\"description\"])\n",
                "print(datapoint[\"features\"])\n",
                "print(datapoint[\"details\"])\n",
                "print(datapoint[\"price\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4d67c339",
            "metadata": {},
            "outputs": [],
            "source": [
                "# How many have prices?\n",
                "prices = 0\n",
                "for datapoint in dataset:\n",
                "    try:\n",
                "        price = float(datapoint[\"price\"])\n",
                "        if price > 0:\n",
                "            prices += 1\n",
                "    except ValueError as e:\n",
                "        pass\n",
                "\n",
                "print(f\"There are {prices:,} with prices which is {prices/len(dataset)*100:,.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f08d34e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# For those with prices, gather the price and the length\n",
                "prices = []\n",
                "lengths = []\n",
                "for datapoint in dataset:\n",
                "    try:\n",
                "        price = float(datapoint[\"price\"])\n",
                "        if price > 0:\n",
                "            prices.append(price)\n",
                "            contents = datapoint[\"title\"] + str(datapoint[\"description\"]) + str(datapoint[\"features\"]) + str(datapoint[\"details\"])\n",
                "            lengths.append(len(contents))\n",
                "    except ValueError as e:\n",
                "        pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "01d372f9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of lengths\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.title(f\"Lengths: Avg {sum(lengths)/len(lengths):,.0f} and highest {max(lengths):,}\\n\")\n",
                "plt.xlabel('Length (chars)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(lengths, rwidth=0.7, color=\"lightblue\", bins=range(0, 6000, 100))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0191163b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of prices\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.2f} and highest {max(prices):,}\\n\")\n",
                "plt.xlabel('Price ($)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(prices, rwidth=0.7, color=\"orange\", bins=range(0, 1000, 10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c03966c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# So what is this item??\n",
                "for datapoint in dataset:\n",
                "    try:\n",
                "        price = float(datapoint[\"price\"])\n",
                "        if price > 21000:\n",
                "            print(datapoint['title'])\n",
                "    except ValueError as e:\n",
                "        pass"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e820e71e",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b style=\"font-size: 16px;\">Reference Product (for Comparison):</b><br>\n",
                "This is the closest I can find — looks like it's going at a bargain price!<br>\n",
                "<a href=\"https://www.amazon.com/TurboChef-Electric-Countertop-Microwave-Convection/dp/B01D05U9NO/\" target=\"_blank\">\n",
                "https://www.amazon.com/TurboChef-Electric-Countertop-Microwave-Convection/dp/B01D05U9NO/\n",
                "</a>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17396064",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>Now It's Time to Curate Our Dataset</b></h5>\n",
                "  We select items that cost between <b>$1 and $999</b>.<br>\n",
                "  For each product, we will create <code>Item</code> instances that:\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em;\">\n",
                "    <li>Truncate the product description to fit within <b>180 tokens</b> using the appropriate tokenizer</li>\n",
                "    <li>Generate a <b>prompt</b> to be used during training</li>\n",
                "  </ul>\n",
                "  Items will be <b>rejected</b> if they do not contain a sufficient number of characters.\n",
                "</div>\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0.8em 0 0 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>But Why 180 Tokens?</b></h5>\n",
                "  A student asked a great question — <i>\"Why are we truncating to 180 tokens? How did we determine that number?\"</i><br>\n",
                "  (Thank you Moataz A. for the excellent question!)<br><br>\n",
                "  The answer: This is a classic example of a <b>hyperparameter</b>. In other words, it's chosen via <b>trial and error</b>.\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em;\">\n",
                "    <li>A high enough token count to give the model useful pricing context</li>\n",
                "    <li>A low enough token count to ensure efficient training</li>\n",
                "  </ul>\n",
                "  I experimented with several values and found that <b>180</b> offered the best balance. You are encouraged to try your own tuning — this type of iteration is a key part of data science research and development.<br><br>\n",
                "  There’s also a practical reason for keeping the token count low: During <b>inference time</b>, we’ll estimate prices for products using short 1–2 sentence descriptions. Our training data should mimic this format for optimal performance.\n",
                "</div>\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0.8em 0 0 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>But I See 160 Tokens in <code>items.py</code>?</b></h5>\n",
                "  Another great question from Moataz A.!<br><br>\n",
                "  Yes — the product description is limited to <b>160 tokens</b> because we prepend and append custom text to format it into a training prompt. That extra context brings the <b>total length</b> to around <b>180 tokens</b>.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "13ac08a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create an Item object for each with a price\n",
                "items = []\n",
                "for datapoint in dataset:\n",
                "    try:\n",
                "        price = float(datapoint[\"price\"])\n",
                "        if price > 0:\n",
                "            item = Item(datapoint, price)\n",
                "            if item.include:\n",
                "                items.append(item)\n",
                "    except ValueError as e:\n",
                "        pass\n",
                "\n",
                "print(f\"There are {len(items):,} items\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb4202b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look at the first item\n",
                "items[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "466b275d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Investigate the prompt that will be used during training - the model learns to complete this\n",
                "print(items[100].prompt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0b857239",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Investigate the prompt that will be used during testing - the model has to complete this\n",
                "print(items[100].test_prompt())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c281fc7c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of token counts\n",
                "tokens = [item.token_count for item in items]\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
                "plt.xlabel('Length (tokens)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(tokens, rwidth=0.7, color=\"green\", bins=range(0, 300, 10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b2e16a74",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of prices\n",
                "prices = [item.price for item in items]\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
                "plt.xlabel('Price ($)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(prices, rwidth=0.7, color=\"purple\", bins=range(0, 300, 10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "895943df",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>Sidenote</b></h5>\n",
                "  If you enjoy the variety of colors used by <code>matplotlib</code> in its charts, you might want to bookmark this:<br>\n",
                "  <a href=\"https://matplotlib.org/stable/gallery/color/named_colors.html\" target=\"_blank\">https://matplotlib.org/stable/gallery/color/named_colors.html</a>\n",
                "</div>\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0.8em 0 0 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>To-Dos for You</b></h5>\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em;\">\n",
                "    <li>Review the <code>Item</code> class and ensure you're comfortable with how it works</li>\n",
                "    <li>Examine a few <code>Item</code> objects — check the training prompt via <code>item.prompt</code> and test prompt with <code>item.test_prompt()</code></li>\n",
                "    <li>Create additional histograms to explore the dataset’s distribution and structure</li>\n",
                "  </ul>\n",
                "</div>\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0.8em 0 0 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>Coming Up Next</b></h5>\n",
                "  We’ll expand the dataset to include additional product categories like <b>Electronics</b> and <b>Automotive</b>.<br>\n",
                "  This will allow us to work with a larger and more diverse dataset, enabling better selection of a balanced and high-quality training set.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "425289b3",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 12px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.4em;\">Examine a few <code>Item</code> objects — look at the training prompt via <code>item.prompt</code> and the test prompt with <code>item.test_prompt()</code></h5>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "efc369ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test Case\n",
                "# Look at the training prompt for an item\n",
                "print(items[0].prompt)\n",
                "\n",
                "# Look at the test prompt for the same item (price removed)\n",
                "print(items[0].test_prompt())\n",
                "\n",
                "# You can repeat for more items, e.g. items[1], items[100]\n",
                "print(items[1].prompt)\n",
                "print(items[1].test_prompt())\n",
                "print(items[100].prompt)\n",
                "print(items[100].test_prompt())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e999add2",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "12836695",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5162b846",
            "metadata": {},
            "source": [
                "#### <code>**day2.ipynb**</code>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "282e423d",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b style=\"font-size: 16px;\">Abstract:</b> Scale up data curation by combining multiple product categories. Balance the dataset by <b>price range</b> and <b>category distribution</b>, and save final <code>train.pkl</code> and <code>test.pkl</code> files for reuse.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88f2e547",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h4 style=\"margin-bottom: 0.2em; font-size: 17px;\"><b>The Product Pricer Continued</b></h4>\n",
                "  A model that can estimate how much something costs, from its description.\n",
                "</div>\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin-top: 0.6em; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 15px;\"><b>Data Curation Part 2</b></h5>\n",
                "  Today we’ll extend our dataset to achieve broader coverage and refine it into a high-quality training dataset.\n",
                "  Data curation might not feel as exciting as model tuning or inference, but it’s a critical part of the LLM engineer’s responsibilities. Mastering this process allows you to build robust commercial solutions grounded in carefully curated data.\n",
                "</div>\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin-top: 0.6em; padding: 0;\">\n",
                "  <b>Dataset Source:</b><br>\n",
                "  <a href=\"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\" target=\"_blank\">https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023</a><br>\n",
                "  <b>Meta Categories Folder:</b><br>\n",
                "  <a href=\"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories\" target=\"_blank\">https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories</a>\n",
                "</div>\n",
                "<div style=\"font-size: 14px; line-height: 1.4; margin-top: 0.6em; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 15px;\"><b>Important Note – Please Read First</b></h5>\n",
                "  We’re about to build a large dataset of <b>400,000 items</b> across multiple product types.\n",
                "  In <b>Week 7</b>, we’ll use this dataset to train our own model. Depending on your GPU, training might take <b>20+ hours</b> and may cost several dollars in compute units.\n",
                "  If you prefer a <b>quicker, lower-cost alternative</b>, use a smaller dataset focused solely on <b>Home Appliances</b>. This covers the same learning goals with slightly reduced accuracy.\n",
                "  Use <code>lite.ipynb</code> for the smaller dataset.\n",
                "  Alternatively, you can skip the curation step by downloading the preprocessed <code>.pkl</code> files:\n",
                "  <a href=\"https://drive.google.com/drive/folders/1f_IZGybvs9o0J5sb3xmtTEQB3BXllzrW\" target=\"_blank\">Download Pickle Files</a>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f679ace5",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import random\n",
                "from dotenv import load_dotenv\n",
                "from huggingface_hub import login\n",
                "from datasets import load_dataset, Dataset, DatasetDict\n",
                "import matplotlib.pyplot as plt\n",
                "from collections import Counter, defaultdict\n",
                "import numpy as np\n",
                "import pickle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8bc71260",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv(override=True)\n",
                "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cfb0c3e6",
            "metadata": {},
            "outputs": [],
            "source": [
                "hf_token = os.environ['HF_TOKEN']\n",
                "login(hf_token, add_to_git_credential=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ea96c4e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from loaders import ItemLoader\n",
                "from items import Item"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bbe6beea",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>The ItemLoader Code</b></h5>\n",
                "Look inside <code>loaders.py</code> — there's some helpful utility code there to make our work easier.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f40ac775",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load in the same dataset as last time\n",
                "items = ItemLoader(\"Appliances\").load()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15660084",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look for a familiar item..\n",
                "print(items[1].prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "31768311",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Now to SCALE UP</b></h5>\n",
                "Let’s explore all datasets that include items typically found in a large home retail store — such as electrical, electronic, and office-related products — but <b>excluding</b> categories like clothes, beauty, and books.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d11041c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_names = [\n",
                "    \"Automotive\",\n",
                "    \"Electronics\",\n",
                "    \"Office_Products\",\n",
                "    \"Tools_and_Home_Improvement\",\n",
                "    \"Cell_Phones_and_Accessories\",\n",
                "    \"Toys_and_Games\",\n",
                "    \"Appliances\",\n",
                "    \"Musical_Instruments\",\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1feb1819",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download all datasets & load into items\n",
                "\n",
                "items = []\n",
                "for dataset_name in dataset_names:\n",
                "    loader = ItemLoader(dataset_name)\n",
                "    items.extend(loader.load())\n",
                "\n",
                "# Now, time for a coffee break!!\n",
                "# By the way, I put the biggest datasets first.. it gets faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "88e2af9d",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"A grand total of {len(items):,} items\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1ff5ba42",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of token counts again\n",
                "tokens = [item.token_count for item in items]\n",
                "\n",
                "if tokens:\n",
                "    plt.figure(figsize=(15, 6))\n",
                "    plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
                "    plt.xlabel('Length (tokens)')\n",
                "    plt.ylabel('Count')\n",
                "    plt.hist(tokens, rwidth=0.7, color=\"skyblue\", bins=range(0, 300, 10))\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"No items to plot. The 'items' list is empty.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9ad14874",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of prices\n",
                "prices = [item.price for item in items]\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
                "plt.xlabel('Price ($)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(prices, rwidth=0.7, color=\"blueviolet\", bins=range(0, 1000, 10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fac76e94",
            "metadata": {},
            "outputs": [],
            "source": [
                "category_counts = Counter()\n",
                "for item in items:\n",
                "    category_counts[item.category]+=1\n",
                "\n",
                "categories = category_counts.keys()\n",
                "counts = [category_counts[category] for category in categories]\n",
                "\n",
                "# Bar chart by category\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.bar(categories, counts, color=\"goldenrod\")\n",
                "plt.title('How many in each category')\n",
                "plt.xlabel('Categories')\n",
                "plt.ylabel('Count')\n",
                "\n",
                "plt.xticks(rotation=30, ha='right')\n",
                "\n",
                "# Add value labels on top of each bar\n",
                "for i, v in enumerate(counts):\n",
                "    plt.text(i, v, f\"{v:,}\", ha='center', va='bottom')\n",
                "\n",
                "# Display the chart\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "67acaf09",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Objective</b></h5>\n",
                "  Craft a dataset that is more balanced in terms of pricing. Aim to:<br>\n",
                "  - Reduce the dominance of low-cost (cheap) items<br>\n",
                "  - Increase the average price to be higher than <b>$60</b><br>\n",
                "  - Balance category representation, specifically by <b>reducing Automotive items</b>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "429a6312",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a dict with a key of each price from $1 to $999\n",
                "# And in the value, put a list of items with that price (to nearest round number)\n",
                "slots = defaultdict(list)\n",
                "for item in items:\n",
                "    slots[round(item.price)].append(item)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5955e160",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a dataset called \"sample\" which tries to more evenly take from the range of prices\n",
                "# And gives more weight to items from categories other than Automotive\n",
                "# Set random seed for reproducibility\n",
                "np.random.seed(42)\n",
                "random.seed(42)\n",
                "sample = []\n",
                "for i in range(1, 1000):\n",
                "    slot = slots[i]\n",
                "    if i>=240:\n",
                "        sample.extend(slot)\n",
                "    elif len(slot) <= 1200:\n",
                "        sample.extend(slot)\n",
                "    else:\n",
                "        weights = np.array([1 if item.category=='Automotive' else 5 for item in slot])\n",
                "        weights = weights / np.sum(weights)\n",
                "        selected_indices = np.random.choice(len(slot), size=1200, replace=False, p=weights)\n",
                "        selected = [slot[i] for i in selected_indices]\n",
                "        sample.extend(selected)\n",
                "\n",
                "print(f\"There are {len(sample):,} items in the sample\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e7dcf43",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of prices in sample\n",
                "prices = [float(item.price) for item in sample]\n",
                "plt.figure(figsize=(15, 10))\n",
                "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
                "plt.xlabel('Price ($)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "daaf3bee",
            "metadata": {},
            "outputs": [],
            "source": [
                "# OK, we did well in terms of raising the average price and having a smooth-ish population of prices\n",
                "# Let's see the categories\n",
                "\n",
                "category_counts = Counter()\n",
                "for item in sample:\n",
                "    category_counts[item.category]+=1\n",
                "\n",
                "categories = category_counts.keys()\n",
                "counts = [category_counts[category] for category in categories]\n",
                "\n",
                "# Create bar chart\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.bar(categories, counts, color=\"lightgreen\")\n",
                "\n",
                "# Customize the chart\n",
                "plt.title('How many in each category')\n",
                "plt.xlabel('Categories')\n",
                "plt.ylabel('Count')\n",
                "\n",
                "plt.xticks(rotation=30, ha='right')\n",
                "\n",
                "# Add value labels on top of each bar\n",
                "for i, v in enumerate(counts):\n",
                "    plt.text(i, v, f\"{v:,}\", ha='center', va='bottom')\n",
                "\n",
                "# Display the chart\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8bd88a15",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Automotive still in the lead, but improved somewhat\n",
                "# For another perspective, let's look at a pie\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "plt.pie(counts, labels=categories, autopct='%1.0f%%', startangle=90)\n",
                "\n",
                "# Add a circle at the center to create a donut chart (optional)\n",
                "centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
                "fig = plt.gcf()\n",
                "fig.gca().add_artist(centre_circle)\n",
                "plt.title('Categories')\n",
                "\n",
                "# Equal aspect ratio ensures that pie is drawn as a circle\n",
                "plt.axis('equal')  \n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2e904509",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Dataset Curated! ✅</b></h5>\n",
                "  We've crafted an excellent dataset. Let's do some final checks.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e91a36cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# How does the price vary with the character count of the prompt?\n",
                "\n",
                "sizes = [len(item.prompt) for item in sample]\n",
                "prices = [item.price for item in sample]\n",
                "\n",
                "# Create the scatter plot\n",
                "plt.figure(figsize=(15, 8))\n",
                "plt.scatter(sizes, prices, s=0.2, color=\"red\")\n",
                "\n",
                "# Add labels and title\n",
                "plt.xlabel('Size')\n",
                "plt.ylabel('Price')\n",
                "plt.title('Is there a simple correlation?')\n",
                "\n",
                "# Display the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e612575f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def report(item):\n",
                "    prompt = item.prompt\n",
                "    tokens = Item.tokenizer.encode(item.prompt)\n",
                "    print(prompt)\n",
                "    print(tokens[-10:])\n",
                "    print(Item.tokenizer.batch_decode(tokens[-10:]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e3eba6a",
            "metadata": {},
            "outputs": [],
            "source": [
                "report(sample[398000])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9c7a8b8f",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Observation</b></h5>\n",
                "  An interesting behavior of the <b>Llama tokenizer</b> is that every number from <b>1 to 999</b> is mapped to a <b>single token</b>, similar to what we observed with <code>gpt-4o</code>.<br>\n",
                "  In contrast, models like <code>qwen2</code>, <code>gemma</code>, and <code>phi3</code> tokenize each digit separately.<br>\n",
                "  While this isn’t a strict requirement, it does provide a slight advantage in our project by making numerical input more compact.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "66b0e847",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Finally</b></h5>\n",
                "  It’s time to split our curated data into <b>training</b>, <b>test</b>, and <b>validation</b> sets.<br>\n",
                "  While it’s typical to allocate around <b>5%–10%</b> of the data for testing, we currently have more data than we need. So we’ll use:\n",
                "  <ul style=\"margin: 0.2em 0; padding-left: 1.5em;\">\n",
                "    <li><b>400,000 samples</b> for training</li>\n",
                "    <li><b>2,000 samples</b> for testing</li>\n",
                "  </ul>\n",
                "  We may not use all the test samples immediately, but they will be helpful for evaluation as we iterate on our models.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "db70be2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(42)\n",
                "random.shuffle(sample)\n",
                "train = sample[:400_000]\n",
                "test = sample[400_000:402_000]\n",
                "print(f\"Divided into a training set of {len(train):,} items and test set of {len(test):,} items\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0593ac2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(train[0].prompt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "debfb78c",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(test[0].test_prompt())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dc4bd337",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the distribution of prices in the first 250 test points\n",
                "\n",
                "prices = [float(item.price) for item in test[:250]]\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
                "plt.xlabel('Price ($)')\n",
                "plt.ylabel('Count')\n",
                "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89cdd1ef",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Finally</b></h5>\n",
                "  Convert your curated dataset into prompt format and upload it to the <b>HuggingFace Hub</b>.<br>\n",
                "  This ensures your dataset is accessible for training and testing, and can be reused or shared across projects.<br>\n",
                "  Make sure to include:\n",
                "  <ul style=\"margin: 0.2em 0; padding-left: 1.5em;\">\n",
                "    <li>Correct formatting (e.g., <code>prompt</code> and <code>price</code> fields)</li>\n",
                "    <li>A clear dataset card with description and metadata</li>\n",
                "    <li>Proper visibility settings (public or private, as needed)</li>\n",
                "  </ul>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0d27a792",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_prompts = [item.prompt for item in train]\n",
                "train_prices = [item.price for item in train]\n",
                "test_prompts = [item.test_prompt() for item in test]\n",
                "test_prices = [item.price for item in test]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f28fdf4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a Dataset from the lists\n",
                "\n",
                "train_dataset = Dataset.from_dict({\"text\": train_prompts, \"price\": train_prices})\n",
                "test_dataset = Dataset.from_dict({\"text\": test_prompts, \"price\": test_prices})\n",
                "dataset = DatasetDict({\n",
                "    \"train\": train_dataset,\n",
                "    \"test\": test_dataset\n",
                "})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94d96cf2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment these lines if you're ready to push to the hub, and replace my name with your HF username\n",
                "\n",
                "# HF_USER = \"ed-donner\"\n",
                "# DATASET_NAME = f\"{HF_USER}/pricer-data\"\n",
                "# dataset.push_to_hub(DATASET_NAME, private=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3526d5f0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# One more thing!\n",
                "# Let's pickle the training and test dataset so we don't have to execute all this code next time!\n",
                "\n",
                "with open('train.pkl', 'wb') as file:\n",
                "    pickle.dump(train, file)\n",
                "\n",
                "with open('test.pkl', 'wb') as file:\n",
                "    pickle.dump(test, file)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5737101",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>To-Dos</b></h5>\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em;\">\n",
                "    <li>Investigate the dataset more!</li>\n",
                "    <li>Confirm that the tokenizer tokenizes all 3-digit prices into a single token</li>\n",
                "  </ul>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c12a528e",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 12px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em;\"><b>1/</b> Investigate the dataset more </h5>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e620bea",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View details of the first 5 items in the sample\n",
                "for i in range(5):\n",
                "    # print(sample[i].prompt)\n",
                "    print(\"Product name:\", sample[i].title)\n",
                "    print(\"Price:\", sample[i].price)\n",
                "    print(\"Category:\", sample[i].category)\n",
                "    print(\"Token count:\", sample[i].token_count)\n",
                "\n",
                "    print(\"\")\n",
                "\n",
                "    # print(\"=\"*40)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4e706150",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 12px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em;\"><b>2/</b> Confirm that the tokenizer tokenizes all 3-digit prices into a single token </h5>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1aadcb01",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check that the tokenizer tokenizes all 3-digit prices into a single token\n",
                "# This is a simple test case to confirm the tokenizer's behavior with 3-digit prices\n",
                "for price in [100, 123, 456, 789, 999]:\n",
                "    tokens = Item.tokenizer.encode(str(price), add_special_tokens=False)\n",
                "    print(f\"Price: {price} -> Tokens: {tokens} (Length: {len(tokens)})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f406d186",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.3em; font-size: 15px;\"><b>Note: <code>add_special_tokens=False</code> in Tokenizer</b></h5>\n",
                "  When calling the <code>encode()</code> method of a tokenizer with <code>add_special_tokens=False</code>, special tokens like <code>&lt;bos&gt;</code>, <code>&lt;eos&gt;</code>, or <code>&lt;pad&gt;</code> will not be added to the encoded output.\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em;\">\n",
                "    <li><b>Purpose:</b> If you only want to tokenize the exact input (e.g., the number <code>\"123\"</code>), the result will contain only the token for <code>\"123\"</code>.</li>\n",
                "    <li>If left as default (<code>add_special_tokens=True</code>), the tokenizer may automatically prepend or append special tokens, leading to more tokens and distorting your token count.</li>\n",
                "  </ul>\n",
                "  <b>Examples:</b><br>\n",
                "  <code>encode(\"123\", add_special_tokens=True)</code> → <code>[&lt;bos&gt;, 4513, &lt;eos&gt;]</code> (3 tokens)<br>\n",
                "  <code>encode(\"123\", add_special_tokens=False)</code> → <code>[4513]</code> (just the token for 123)\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8f5b3be",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7a27be3d",
            "metadata": {},
            "source": [
                "#### <code>**day3.ipynb**</code>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "47e09435",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b style=\"font-size: 16px;\">Abstract:</b> Build baseline models for the Product Pricer using classical ML approaches: <b>Linear Regression</b>, <b>Bag of Words</b>, <b>Word2Vec</b>, <b>Support Vector Machine</b>, and <b>Random Forest</b>. Benchmark performance using a custom <code>Tester</code> class.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d11494fb",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h4 style=\"margin-bottom: 0.2em; font-size: 18px;\"><b>The Product Pricer Continued</b></h4>\n",
                "  A model that can estimate how much something costs, from its description.\n",
                "</div>\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0.5em 0 0 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Baseline Models</b></h5>\n",
                "  Today we work on the simplest models to act as a starting point that we will beat.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f0df82d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import math\n",
                "import json\n",
                "import random\n",
                "import pickle\n",
                "from collections import Counter\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "from huggingface_hub import login\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "from sklearn.preprocessing import StandardScaler"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a37acec3",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>NLP Imports</b></h5>\n",
                "  In the next cell, we import additional packages for NLP-related machine learning tasks.<br>\n",
                "  If the <code>gensim</code> import raises an error such as:<br>\n",
                "  <i>\"Cannot import name 'triu' from 'scipy.linalg'\"</i><br>\n",
                "  Please fix it by running the following command in a separate cell:<br>\n",
                "  <code>!pip install \"scipy&lt;1.13\"</code><br>\n",
                "  This issue is discussed in detail on StackOverflow: \n",
                "  <a href=\"https://stackoverflow.com/questions/78279136/importerror-cannot-import-name-triu-from-scipy-linalg-when-importing-gens\" target=\"_blank\">link to fix</a>.<br>\n",
                "  Special thanks to students <b>Arnaldo G</b> and <b>Ard V</b> for identifying and resolving this issue.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48d411a9",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.4; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Sidenote: NLP (Natural Language Processing)</b></h5>\n",
                "  NLP stands for <b>Natural Language Processing</b>. It is a field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language.\n",
                "  NLP imports refer to Python packages and modules that provide tools and algorithms for working with text data. These typically include libraries for:\n",
                "  <ul style=\"margin: 0.4em 0; padding-left: 1.5em; font-size: 14px;\">\n",
                "    <li>Text preprocessing (tokenization, stemming, lemmatization)</li>\n",
                "    <li>Feature extraction (Bag of Words, TF-IDF, embeddings)</li>\n",
                "    <li>Machine learning models for text (classification, regression, clustering)</li>\n",
                "    <li>Utilities for handling and visualizing text data</li>\n",
                "  </ul>\n",
                "  <b  style=\"margin-bottom: 0.2em; font-size: 16px;\">Examples of common NLP imports:</b>\n",
                "  <pre style=\"margin: 0; padding: 0.6em; font-size: 14px;\">\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from gensim.models import Word2Vec\n",
                "from transformers import AutoTokenizer, AutoModel\n",
                "  </pre>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "858dde3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# NLP-related Imports\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from gensim.models import Word2Vec\n",
                "from gensim.utils import simple_preprocess"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9c35a4d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# More imports for advanced ML\n",
                "from sklearn.svm import LinearSVR\n",
                "from sklearn.ensemble import RandomForestRegressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c849d54a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Constants - used for printing to stdout in color\n",
                "GREEN = \"\\033[92m\"\n",
                "YELLOW = \"\\033[93m\"\n",
                "RED = \"\\033[91m\"\n",
                "RESET = \"\\033[0m\"\n",
                "COLOR_MAP = {\"red\":RED, \"orange\": YELLOW, \"green\": GREEN}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "17450e6c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "\n",
                "# Environment\n",
                "load_dotenv(override=True)\n",
                "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d6996e35",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log in to HuggingFace\n",
                "hf_token = os.environ['HF_TOKEN']\n",
                "login(hf_token, add_to_git_credential=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0615e44a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# One more import after logging in\n",
                "from items import Item"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f85a208d",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px\"><b>Loading the <code>.pkl</code> Files</b></h5>\n",
                "  Let’s avoid curating all our data again! Load the previously saved pickle files instead.<br><br>\n",
                "  If you didn’t create these in <b>Day 2</b>, you can download them from the instructor’s Google Drive (you’ll also find the slides here):<br>\n",
                "  <a href=\"https://drive.google.com/drive/folders/1JwNorpRHdnf_pU0GE5yYtfKlyrKC3CoV?usp=sharing\" target=\"_blank\">https://drive.google.com/drive/folders/1JwNorpRHdnf_pU0GE5yYtfKlyrKC3CoV?usp=sharing</a><br><br>\n",
                "  <b>Note:</b> The files are quite large — you may want to grab a coffee!\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8d601866",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('train.pkl', 'rb') as file:\n",
                "    train = pickle.load(file)\n",
                "\n",
                "with open('test.pkl', 'rb') as file:\n",
                "    test = pickle.load(file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b98d9d70",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remind ourselves the training prompt\n",
                "print(train[0].prompt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee742101",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remind a test prompt\n",
                "print(train[0].price)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "328b5811",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\"><h5 style=\"margin-bottom: 0.2em;\"><b>Unveiling a Mighty Script That We Will Use a Lot!</b></h5>A rather pleasing <b>Test Harness</b> that evaluates any model against <b>250 items</b> from the test set, and shows the results in a visually satisfying way.<br>You write a function of this form:<pre style=\"padding: 0.5em; margin: 0.5em 0;\"><code>def my_prediction_function(item):\n",
                "    # my code here\n",
                "    return my_estimate</code></pre>And then you call:<br><code>Tester.test(my_prediction_function)</code><br>to evaluate your model.</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f4fc4c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Tester:\n",
                "\n",
                "    def __init__(self, predictor, title=None, data=test, size=250):\n",
                "        self.predictor = predictor\n",
                "        self.data = data\n",
                "        self.title = title or predictor.__name__.replace(\"_\", \" \").title()\n",
                "        self.size = size\n",
                "        self.guesses = []\n",
                "        self.truths = []\n",
                "        self.errors = []\n",
                "        self.sles = []\n",
                "        self.colors = []\n",
                "\n",
                "    def color_for(self, error, truth):\n",
                "        if error<40 or error/truth < 0.2:\n",
                "            return \"green\"\n",
                "        elif error<80 or error/truth < 0.4:\n",
                "            return \"orange\"\n",
                "        else:\n",
                "            return \"red\"\n",
                "    \n",
                "    def run_datapoint(self, i):\n",
                "        datapoint = self.data[i]\n",
                "        guess = self.predictor(datapoint)\n",
                "        truth = datapoint.price\n",
                "        error = abs(guess - truth)\n",
                "        log_error = math.log(truth+1) - math.log(guess+1)\n",
                "        sle = log_error ** 2\n",
                "        color = self.color_for(error, truth)\n",
                "        title = datapoint.title if len(datapoint.title) <= 40 else datapoint.title[:40]+\"...\"\n",
                "        self.guesses.append(guess)\n",
                "        self.truths.append(truth)\n",
                "        self.errors.append(error)\n",
                "        self.sles.append(sle)\n",
                "        self.colors.append(color)\n",
                "        print(f\"{COLOR_MAP[color]}{i+1}: Guess: ${guess:,.2f} Truth: ${truth:,.2f} Error: ${error:,.2f} SLE: {sle:,.2f} Item: {title}{RESET}\")\n",
                "\n",
                "    def chart(self, title):\n",
                "        max_error = max(self.errors)\n",
                "        plt.figure(figsize=(12, 8))\n",
                "        max_val = max(max(self.truths), max(self.guesses))\n",
                "        plt.plot([0, max_val], [0, max_val], color='deepskyblue', lw=2, alpha=0.6)\n",
                "        plt.scatter(self.truths, self.guesses, s=3, c=self.colors)\n",
                "        plt.xlabel('Ground Truth')\n",
                "        plt.ylabel('Model Estimate')\n",
                "        plt.xlim(0, max_val)\n",
                "        plt.ylim(0, max_val)\n",
                "        plt.title(title)\n",
                "        plt.show()\n",
                "\n",
                "    def report(self):\n",
                "        average_error = sum(self.errors) / self.size\n",
                "        rmsle = math.sqrt(sum(self.sles) / self.size)\n",
                "        hits = sum(1 for color in self.colors if color==\"green\")\n",
                "        title = f\"{self.title} Error=${average_error:,.2f} RMSLE={rmsle:,.2f} Hits={hits/self.size*100:.1f}%\"\n",
                "        self.chart(title)\n",
                "\n",
                "    def run(self):\n",
                "        self.error = 0\n",
                "        for i in range(self.size):\n",
                "            self.run_datapoint(i)\n",
                "        self.report()\n",
                "\n",
                "    @classmethod\n",
                "    def test(cls, function):\n",
                "        cls(function).run()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "16d406cf",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em;\"><b>Now for Something Basic</b></h5>\n",
                "  What's the very simplest model you could imagine?<br>\n",
                "  Let's start with a <b>random number generator!</b>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1f947a81",
            "metadata": {},
            "outputs": [],
            "source": [
                "def random_pricer(item):\n",
                "    return random.randrange(1,1000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "07f1b81c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the random seed\n",
                "random.seed(42)\n",
                "\n",
                "# Run our TestRunner\n",
                "Tester.test(random_pricer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "786759a9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# That was fun!\n",
                "# We can do better - here's another rather trivial model\n",
                "\n",
                "training_prices = [item.price for item in train]\n",
                "training_average = sum(training_prices) / len(training_prices)\n",
                "\n",
                "def constant_pricer(item):\n",
                "    return training_average"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b2b4ef60",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run our constant predictor\n",
                "Tester.test(constant_pricer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "333ce0fa",
            "metadata": {},
            "outputs": [],
            "source": [
                "train[0].details"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1c3b5072",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a new \"features\" field on items, and populate it with json parsed from the details dict\n",
                "\n",
                "for item in train:\n",
                "    item.features = json.loads(item.details)\n",
                "for item in test:\n",
                "    item.features = json.loads(item.details)\n",
                "\n",
                "# Look at one"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7596ad7",
            "metadata": {},
            "outputs": [],
            "source": [
                "train[0].features.keys()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb2d7334",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look at 20 most common features in training set\n",
                "\n",
                "feature_count = Counter()\n",
                "for item in train:\n",
                "    for f in item.features.keys():\n",
                "        feature_count[f]+=1\n",
                "\n",
                "feature_count.most_common(40)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bc699fa0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Now some janky code to pluck out the Item Weight\n",
                "# Don't worry too much about this: spoiler alert, it's not going to be much use in training!\n",
                "\n",
                "def get_weight(item):\n",
                "    weight_str = item.features.get('Item Weight')\n",
                "    if weight_str:\n",
                "        parts = weight_str.split(' ')\n",
                "        amount = float(parts[0])\n",
                "        unit = parts[1].lower()\n",
                "        if unit==\"pounds\":\n",
                "            return amount\n",
                "        elif unit==\"ounces\":\n",
                "            return amount / 16\n",
                "        elif unit==\"grams\":\n",
                "            return amount / 453.592\n",
                "        elif unit==\"milligrams\":\n",
                "            return amount / 453592\n",
                "        elif unit==\"kilograms\":\n",
                "            return amount / 0.453592\n",
                "        elif unit==\"hundredths\" and parts[2].lower()==\"pounds\":\n",
                "            return amount / 100\n",
                "        else:\n",
                "            print(weight_str)\n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae56ff99",
            "metadata": {},
            "outputs": [],
            "source": [
                "weights = [get_weight(t) for t in train]\n",
                "weights = [w for w in weights if w]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "11dc5d2e",
            "metadata": {},
            "outputs": [],
            "source": [
                "average_weight = sum(weights)/len(weights)\n",
                "average_weight"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b4733f76",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_weight_with_default(item):\n",
                "    weight = get_weight(item)\n",
                "    return weight or average_weight"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e3bc7662",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_rank(item):\n",
                "    rank_dict = item.features.get(\"Best Sellers Rank\")\n",
                "    if rank_dict:\n",
                "        ranks = rank_dict.values()\n",
                "        return sum(ranks)/len(ranks)\n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb120ab7",
            "metadata": {},
            "outputs": [],
            "source": [
                "ranks = [get_rank(t) for t in train]\n",
                "ranks = [r for r in ranks if r]\n",
                "average_rank = sum(ranks)/len(ranks)\n",
                "average_rank"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6ed8cac",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_rank_with_default(item):\n",
                "    rank = get_rank(item)\n",
                "    return rank or average_rank"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "91870413",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_text_length(item):\n",
                "    return len(item.test_prompt())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0cd08667",
            "metadata": {},
            "outputs": [],
            "source": [
                "# investigate the brands\n",
                "\n",
                "brands = Counter()\n",
                "for t in train:\n",
                "    brand = t.features.get(\"Brand\")\n",
                "    if brand:\n",
                "        brands[brand]+=1\n",
                "\n",
                "# Look at most common 40 brands\n",
                "\n",
                "brands.most_common(40)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96f8d2ed",
            "metadata": {},
            "outputs": [],
            "source": [
                "TOP_ELECTRONICS_BRANDS = [\"hp\", \"dell\", \"lenovo\", \"samsung\", \"asus\", \"sony\", \"canon\", \"apple\", \"intel\"]\n",
                "def is_top_electronics_brand(item):\n",
                "    brand = item.features.get(\"Brand\")\n",
                "    return brand and brand.lower() in TOP_ELECTRONICS_BRANDS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f0e47f57",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_features(item):\n",
                "    return {\n",
                "        \"weight\": get_weight_with_default(item),\n",
                "        \"rank\": get_rank_with_default(item),\n",
                "        \"text_length\": get_text_length(item),\n",
                "        \"is_top_electronics_brand\": 1 if is_top_electronics_brand(item) else 0\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6d30861e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look at features in a training item\n",
                "get_features(train[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a0828de",
            "metadata": {},
            "outputs": [],
            "source": [
                "# A utility function to convert our features into a pandas dataframe\n",
                "\n",
                "def list_to_dataframe(items):\n",
                "    features = [get_features(item) for item in items]\n",
                "    df = pd.DataFrame(features)\n",
                "    df['price'] = [item.price for item in items]\n",
                "    return df\n",
                "\n",
                "train_df = list_to_dataframe(train)\n",
                "test_df = list_to_dataframe(test[:250])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f72dd8e",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em;\"><b>Traditional Linear Regression</b></h5>\n",
                "  This approach implements a classic machine learning approach - Linear Regression - to predict product prices based on a set of numeric features.\n",
                "  <br><br>\n",
                "  <b>Why \"Traditional\"?</b><br>\n",
                "  <ul style=\"margin: 0.5em 0; padding-left: 1.5em;\">\n",
                "    <li>Linear Regression is one of the oldest and most fundamental algorithms in statistics and machine learning.</li>\n",
                "    <li>It models the relationship between a dependent variable (here, price) and one or more independent variables (here, weight, rank, text_length, is_top_electronics_brand) by fitting a linear equation to observed data.</li>\n",
                "    <li>It does not use neural networks, embeddings, or advanced NLP techniques - just numeric features and a linear model.</li>\n",
                "  </ul>\n",
                "  <b>In context:</b><br>\n",
                "  This notebook benchmarks <i>\"traditional\"</i> ML models like Linear Regression before moving on to more advanced or modern approaches (such as Bag of Words, Word2Vec, Random Forest, or LLMs). This provides a baseline for comparison.<br><br>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b201923",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Traditional Linear Regression\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "# Separate features and target\n",
                "feature_columns = ['weight', 'rank', 'text_length', 'is_top_electronics_brand']\n",
                "\n",
                "X_train = train_df[feature_columns]\n",
                "y_train = train_df['price']\n",
                "X_test = test_df[feature_columns]\n",
                "y_test = test_df['price']\n",
                "\n",
                "# Train a Linear Regression\n",
                "model = LinearRegression()\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "for feature, coef in zip(feature_columns, model.coef_):\n",
                "    print(f\"{feature}: {coef}\")\n",
                "print(f\"Intercept: {model.intercept_}\")\n",
                "\n",
                "# Predict the test set and evaluate\n",
                "y_pred = model.predict(X_test)\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "\n",
                "print(f\"Mean Squared Error: {mse}\")\n",
                "print(f\"R-squared Score: {r2}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "27950a99",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to predict price for a new item\n",
                "\n",
                "def linear_regression_pricer(item):\n",
                "    features = get_features(item)\n",
                "    features_df = pd.DataFrame([features])\n",
                "    return model.predict(features_df)[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "13d6a63c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# test it\n",
                "\n",
                "Tester.test(linear_regression_pricer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f5832be",
            "metadata": {},
            "outputs": [],
            "source": [
                "# For the next few models, we prepare our documents and prices\n",
                "# Note that we use the test prompt for the documents, otherwise we'll reveal the answer!!\n",
                "\n",
                "prices = np.array([float(item.price) for item in train])\n",
                "documents = [item.test_prompt() for item in train]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5e14303f",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em;\"><b>Bag of Words (BoW)</b></h5>\n",
                "  This approach below implements a <b>Bag of Words</b> model - one of the earliest and simplest techniques for extracting features from text in natural language processing.\n",
                "  <br><br>\n",
                "  <b>What is Bag of Words?</b><br>\n",
                "  <ul style=\"margin: 0.5em 0; padding-left: 1.5em;\">\n",
                "    <li>It converts text into numerical feature vectors by counting word occurrences, ignoring grammar and word order.</li>\n",
                "    <li>The result is a sparse representation of the text, where each feature corresponds to a word in the vocabulary.</li>\n",
                "    <li>It is commonly used with linear models, such as Logistic or Linear Regression, for classification or regression tasks.</li>\n",
                "  </ul>\n",
                "  <b>In context:</b><br>\n",
                "  BoW serves as a strong baseline for NLP tasks, despite its simplicity. In this notebook, it is used as a step up from pure numeric features, incorporating actual text data into the model. While it lacks semantic understanding, BoW often delivers surprisingly solid results and helps establish a benchmark before progressing to more complex techniques like Word2Vec or transformer-based models.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b7c063c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the CountVectorizer for a Bag of Words model\n",
                "\n",
                "np.random.seed(42)\n",
                "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
                "X = vectorizer.fit_transform(documents)\n",
                "regressor = LinearRegression()\n",
                "regressor.fit(X, prices)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d207da51",
            "metadata": {},
            "outputs": [],
            "source": [
                "def bow_lr_pricer(item):\n",
                "    x = vectorizer.transform([item.test_prompt()])\n",
                "    return max(regressor.predict(x)[0], 0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5c87ce8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# test it\n",
                "\n",
                "Tester.test(bow_lr_pricer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1f05f6e",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Word2Vec Model</b></h5>\n",
                "This approach below uses the Word2Vec technique to embed each word in the product description into a high-dimensional vector and then aggregates these vectors to predict product prices using a regression model.<br><br>\n",
                "<b>Why \"Word2Vec\"?</b><br>\n",
                "Word2Vec is a word embedding model that captures semantic relationships between words based on their context in large corpora. Unlike Bag of Words, it encodes meaning and similarity between words.<br><br>\n",
                "- Each word is mapped to a dense vector based on its usage.<br>\n",
                "- Vectors from a product’s description are typically averaged or pooled to represent the entire item.<br>\n",
                "- The resulting feature vectors are then used in downstream models like regression.<br><br>\n",
                "<b>In context:</b><br>\n",
                "This model bridges the gap between traditional BoW and modern transformer-based approaches. It shows how adding semantic information through word embeddings can improve performance over frequency-based methods. It also sets the stage for evaluating even more powerful models like LLMs later in the notebook.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ef2c589a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# The amazing word2vec model, implemented in gensim NLP library\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "# Preprocess the documents\n",
                "processed_docs = [simple_preprocess(doc) for doc in documents]\n",
                "\n",
                "# Train Word2Vec model\n",
                "w2v_model = Word2Vec(sentences=processed_docs, vector_size=400, window=5, min_count=1, workers=8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ebae03f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# This step of averaging vectors across the document is a weakness in our approach\n",
                "\n",
                "def document_vector(doc):\n",
                "    doc_words = simple_preprocess(doc)\n",
                "    word_vectors = [w2v_model.wv[word] for word in doc_words if word in w2v_model.wv]\n",
                "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(w2v_model.vector_size)\n",
                "\n",
                "# Create feature matrix\n",
                "X_w2v = np.array([document_vector(doc) for doc in documents])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eaf2760a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Linear Regression on word2vec\n",
                "\n",
                "word2vec_lr_regressor = LinearRegression()\n",
                "word2vec_lr_regressor.fit(X_w2v, prices)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5cb483cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "def word2vec_lr_pricer(item):\n",
                "    doc = item.test_prompt()\n",
                "    doc_vector = document_vector(doc)\n",
                "    return max(0, word2vec_lr_regressor.predict([doc_vector])[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae79b514",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tester.test(word2vec_lr_pricer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "461489a1",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Support Vector Machine (SVM) Model</b></h5>\n",
                "This approach below applies a Support Vector Machine regression model (SVR) to predict product prices based on structured features extracted from item descriptions.<br><br>\n",
                "<b>Why \"Support Vector Machine\"?</b><br>\n",
                "SVM is a powerful and versatile supervised learning algorithm that works well for both classification and regression tasks.<br><br>\n",
                "- In regression, SVR tries to fit the best possible function within a margin of tolerance from the actual data points.<br>\n",
                "- It is effective for handling high-dimensional feature spaces and non-linear relationships when used with appropriate kernels.<br>\n",
                "- In this notebook, we typically use features like weight, rank, text length, and brand indicator to feed into the SVR model.<br><br>\n",
                "<b>In context:</b><br>\n",
                "This model represents another strong baseline from traditional machine learning. It allows us to evaluate how well a non-linear ML algorithm performs before moving to embedding-based or neural models. SVM often excels with well-engineered features and is included here as part of our progression through baseline comparisons.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e9fc681",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Support Vector Machines\n",
                "\n",
                "np.random.seed(42)\n",
                "svr_regressor = LinearSVR()\n",
                "\n",
                "svr_regressor.fit(X_w2v, prices)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d4ef3f94",
            "metadata": {},
            "outputs": [],
            "source": [
                "def svr_pricer(item):\n",
                "    np.random.seed(42)\n",
                "    doc = item.test_prompt()\n",
                "    doc_vector = document_vector(doc)\n",
                "    return max(float(svr_regressor.predict([doc_vector])[0]),0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fd8787b",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tester.test(svr_pricer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88794d5b",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Random Forest Model</b></h5>\n",
                "This approach below uses a <b>Random Forest Regressor</b> to estimate product prices based on structured features extracted from the dataset.<br><br>\n",
                "<b>Why \"Random Forest\"?</b><br>\n",
                "Random Forest is an ensemble learning method that builds multiple decision trees and combines their predictions to improve accuracy and reduce overfitting.<br><br>\n",
                "- It is robust to noise and outliers, and works well with both linear and non-linear data.<br>\n",
                "- Each decision tree in the forest is trained on a random subset of the data (with replacement), which adds diversity to the ensemble.<br>\n",
                "- Predictions are typically made by averaging the outputs of all trees (in regression tasks).<br><br>\n",
                "<b>In context:</b><br>\n",
                "Random Forest provides a powerful baseline for structured data. In this notebook, it's used to benchmark performance against other traditional models like Linear Regression, SVM, and modern techniques such as embeddings or LLMs. Its strength lies in its ability to model complex feature interactions without much preprocessing.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cf93218a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# And the powerful Random Forest regression\n",
                "# This usually takes about 10 minutes or more to train\n",
                "\n",
                "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=8)\n",
                "rf_model.fit(X_w2v, prices)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5765549",
            "metadata": {},
            "outputs": [],
            "source": [
                "def random_forest_pricer(item):\n",
                "    doc = item.test_prompt()\n",
                "    doc_vector = document_vector(doc)\n",
                "    return max(0, rf_model.predict([doc_vector])[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ed045f48",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tester.test(random_forest_pricer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7cabbc6e",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\"><b>Summary of Regression Models</b></h5></div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dfd3082f",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 12px; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\"><b>1. General Scenarios</b></h5></div>\n",
                "\n",
                "<table style=\"font-size: 14px; line-height: 1.4; border-collapse: collapse; width: 100%; margin: 0; padding: 0;\">\n",
                "  <thead>\n",
                "    <tr>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px; text-align: center;\">Model</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px; text-align: center;\">Main Input Type</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px; text-align: center;\">How It Works (Simple)</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px; text-align: center;\">Main Strengths</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px; text-align: center;\">Main Weaknesses</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px; text-align: center;\">When to Use?</th>\n",
                "    </tr>\n",
                "  </thead>\n",
                "  <tbody>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Linear Regression</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Numeric features</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Finds a straight line that best fits the data</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Fast, simple, easy to explain</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Misses complex (non-linear) patterns</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Data is mostly numbers, simple trends</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Bag of Words (BoW)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Text (word counts)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Counts how often each word appears in the text</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Simple, works for basic text tasks</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Ignores word meaning/context</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Text data, quick baseline</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Word2Vec</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Text (embeddings)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Turns words into vectors that capture meaning</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Understands word meaning, context</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Needs lots of data, loses sentence info</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">When meaning of words matters</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">SVM (SVR)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Numeric/vectors</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Finds a boundary (can be curved) to fit the data</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Good for complex, non-linear data</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Slow with big data, hard to explain</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Medium-sized, tricky data</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Random Forest</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Numeric/vectors</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Combines many decision trees for better predictions</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Handles complex data, robust</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Can be slow, less interpretable</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Complex data, many features</td>\n",
                "    </tr>\n",
                "  </tbody>\n",
                "</table>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c65bf529",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 12px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\"><b>2. This notebook</b></h5></div>\n",
                "\n",
                "<table style=\"font-size: 14px; line-height: 1.4; border-collapse: collapse; width: 100%; margin: 0; padding: 0;\">\n",
                "  <thead>\n",
                "    <tr>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Model</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Input Source</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Feature Extraction</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Setup Difficulty</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Accuracy (Typical)</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Practical Strengths</th>\n",
                "      <th style=\"border: 1px solid #ccc; padding: 6px;\">Practical Weaknesses</th>\n",
                "    </tr>\n",
                "  </thead>\n",
                "  <tbody>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Linear Regression</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Numeric features (weight, etc.)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Uses product info (weight, rank, etc.)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Easy</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Low (baseline)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Fast, easy to understand</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Ignores text descriptions</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Bag of Words (BoW)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Product description text</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Counts words in product description</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Medium</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Medium</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Uses text, simple to try</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Misses word meaning/context</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Word2Vec</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Product description text</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Averages word vectors from Word2Vec</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Higher</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Higher than BoW</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Captures some meaning from text</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Loses sentence structure</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">SVM (SVR)</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Word2Vec vectors</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Uses Word2Vec output as input</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">High</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Good for non-linear</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Can model complex patterns</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Slow, not scalable to huge data</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Random Forest</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Word2Vec vectors</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Uses Word2Vec output as input</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">High</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Often best</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Handles complex, messy data well</td>\n",
                "      <td style=\"border: 1px solid #ccc; padding: 6px;\">Hard to explain, uses more resources</td>\n",
                "    </tr>\n",
                "  </tbody>\n",
                "</table>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17382efa",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9925339a",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2cae8fed",
            "metadata": {},
            "source": [
                "#### <code>**day4.ipynb**</code>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dceb3ac0",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b style=\"font-size: 16px;\">Abstract:</b> Evaluate the performance of <b>Frontier LLMs</b> - including <b>GPT-4o-mini, GPT-4o, <s>Claude 3.5 Sonnet</s> and Llama3.2</b> - on the Product Pricer dataset. Compare their effectiveness against traditional ML models using the same test set.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c9ffd6c",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h4 style=\"margin-bottom: 0.2em; font-size: 18px;\"><b>The Product Pricer Continued</b></h4>\n",
                "A model that can estimate how much something costs, from its description.\n",
                "</div>\n",
                "<br>\n",
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Enter The Frontier!</b></h5>\n",
                "And now – we put Frontier Models to the test.\n",
                "</div>\n",
                "<br>\n",
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b>2 important points:</b><br>\n",
                "It’s important to appreciate that we <b>aren’t training</b> the frontier models. We’re only providing them with the Test dataset to see how they perform. They don’t gain the benefit of the 400,000 training examples that we provided to the Traditional ML models.<br>\n",
                "<br>\n",
                "<b>HAVING SAID THAT...</b><br>\n",
                "It’s entirely possible that in their monstrously large training data, they’ve already been exposed to all the products in the training AND the test set. So there could be test “contamination” here which gives them an unfair advantage. We should keep that in mind.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4d740d24",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import math\n",
                "import json\n",
                "import random\n",
                "from dotenv import load_dotenv\n",
                "from huggingface_hub import login\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pickle\n",
                "from collections import Counter\n",
                "from openai import OpenAI\n",
                "from anthropic import Anthropic\n",
                "import ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b782f66",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv(override=True)\n",
                "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2cedccfa",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log in to HuggingFace\n",
                "\n",
                "hf_token = os.environ['HF_TOKEN']\n",
                "login(hf_token, add_to_git_credential=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f1f346e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# moved our Tester into a separate package\n",
                "# call it with Tester.test(function_name, test_dataset)\n",
                "\n",
                "from items import Item\n",
                "from testing import Tester"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5691b95",
            "metadata": {},
            "outputs": [],
            "source": [
                "openai = OpenAI()\n",
                "claude = Anthropic()\n",
                "llama_client = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a34d6c3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's avoid curating all our data again! Load in the pickle files:\n",
                "\n",
                "with open('train.pkl', 'rb') as file:\n",
                "    train = pickle.load(file)\n",
                "\n",
                "with open('test.pkl', 'rb') as file:\n",
                "    test = pickle.load(file)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1576e29f",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Before we look at the Frontier</b></h5>\n",
                "There is one more model we could consider\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5022919",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write the test set to a CSV\n",
                "\n",
                "import csv\n",
                "with open('human_input.csv', 'w', encoding=\"utf-8\") as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    for t in test[:250]:\n",
                "        writer.writerow([t.test_prompt(), 0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f9635062",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read it back in\n",
                "\n",
                "human_predictions = []\n",
                "with open('human_output.csv', 'r', encoding=\"utf-8\") as csvfile:\n",
                "    reader = csv.reader(csvfile)\n",
                "    for row in reader:\n",
                "        human_predictions.append(float(row[1]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d4e590f4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def human_pricer(item):\n",
                "    idx = test.index(item)\n",
                "    return human_predictions[idx]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e973a6f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tester.test(human_pricer, test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9f141646",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\"><b>1/ GPT-4o-mini</b></h5>\n",
                "Note: It’s called <i>mini</i>, but it packs a punch.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "036af2b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# First let's work on a good prompt for a Frontier model\n",
                "# Notice that I'm removing the \" to the nearest dollar\"\n",
                "# When we train our own models, we'll need to make the problem as easy as possible, \n",
                "# but a Frontier model needs no such simplification.\n",
                "\n",
                "def messages_for(item):\n",
                "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
                "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
                "    return [\n",
                "        {\"role\": \"system\", \"content\": system_message},\n",
                "        {\"role\": \"user\", \"content\": user_prompt},\n",
                "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c771b0d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try this out\n",
                "\n",
                "messages_for(test[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c64d4b27",
            "metadata": {},
            "outputs": [],
            "source": [
                "# A utility function to extract the price from a string\n",
                "\n",
                "def get_price(s):\n",
                "    s = s.replace('$','').replace(',','')\n",
                "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
                "    return float(match.group()) if match else 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "518a05a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "get_price(\"The price is roughly $99.99 because blah blah\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d322c86",
            "metadata": {},
            "outputs": [],
            "source": [
                "# The function for gpt-4o-mini\n",
                "\n",
                "def gpt_4o_mini(item):\n",
                "    response = openai.chat.completions.create(\n",
                "        model=\"gpt-4o-mini\", \n",
                "        messages=messages_for(item),\n",
                "        seed=42,\n",
                "        max_tokens=5\n",
                "    )\n",
                "    reply = response.choices[0].message.content\n",
                "    return get_price(reply)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8296863e",
            "metadata": {},
            "outputs": [],
            "source": [
                "test[0].price"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d984adcd",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# 11:57 9/7: hit the rate limit \n",
                "\n",
                "# Run the Tester on gpt-4o-mini with the first 10 items in the test set\n",
                "# print(\"Testing gpt-4o-mini on the first 10 items in the test set\")\n",
                "# for i, item in enumerate(test[:10]):\n",
                "for i, item in enumerate(test[:9]):\n",
                "    guess = gpt_4o_mini(item)\n",
                "    truth = item.price\n",
                "    error = abs(guess - truth)\n",
                "    print(f\"{i+1}: Guess: ${guess:,.2f} | Truth: ${truth:,.2f} | Error: ${error:,.2f} | Item: {item.title[:40]}...\")\n",
                "    time.sleep(20)\n",
                "\n",
                "# # Run the Tester on gpt-4o-mini with a larger test set\n",
                "# print(\"Testing gpt-4o-mini on the first 250 items in the test set\")\n",
                "# Tester = Tester(gpt_4o_mini, title=\"gpt-4o-mini\", data=test, size=250)\n",
                "# Tester.run()\n",
                "\n",
                "# Run the Tester on gpt-4o-mini with the full test set\n",
                "# This will take about 20 - 40 minutes depending on internet speed and the model's response time\n",
                "# print(\"Running Tester on gpt-4o-mini with the full test set\")\n",
                "# Tester = Tester(gpt_4o_mini, title=\"gpt-4o-mini\", data=test, size=2000)\n",
                "# Tester.run()\n",
                "\n",
                "# Run the Tester on gpt-4o-mini with the full test set\n",
                "# Tester = Tester(gpt_4o_mini, title=\"gpt-4o-mini\", data=test, size=len(test))\n",
                "# Tester.run()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2c0b6b4c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def gpt_4o_frontier(item):\n",
                "    response = openai.chat.completions.create(\n",
                "        model=\"gpt-4o-2024-08-06\", \n",
                "        messages=messages_for(item),\n",
                "        seed=42,\n",
                "        max_tokens=5\n",
                "    )\n",
                "    reply = response.choices[0].message.content\n",
                "    return get_price(reply)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cff369e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# The function for gpt-4o - the August model\n",
                "# Note that it cost me about 1-2 cents to run this (pricing may vary by region)\n",
                "# You can skip this and look at my results instead\n",
                "\n",
                "Tester.test(gpt_4o_frontier, test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eee12939",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\"><b>2/ Claude-3.5-sonnet</b></h5>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd305d00",
            "metadata": {},
            "outputs": [],
            "source": [
                "def claude_3_point_5_sonnet(item):\n",
                "    messages = messages_for(item)\n",
                "    system_message = messages[0]['content']\n",
                "    messages = messages[1:]\n",
                "    response = claude.messages.create(\n",
                "        model=\"claude-3-5-sonnet-20240620\",\n",
                "        max_tokens=5,\n",
                "        system=system_message,\n",
                "        messages=messages\n",
                "    )\n",
                "    reply = response.content[0].text\n",
                "    return get_price(reply)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c96e3c4e",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tester.test(claude_3_point_5_sonnet, test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb0deb4f",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<h5 style=\"margin-bottom: 0.2em;\"><b>3/ Llama3.2 (local)</b></h5>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1bf504d3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def llama3_2_local(item):\n",
                "    response = llama_client.chat.completions.create(\n",
                "        model=\"llama3.2\",\n",
                "        messages=messages_for(item),\n",
                "        seed=42,\n",
                "        max_tokens=5\n",
                "    )\n",
                "    reply = response.choices[0].message.content\n",
                "    return get_price(reply)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "083556a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# 10 first items\n",
                "# print(\"Running Tester on llama3.2 with the first 10 items of the test set\")\n",
                "# for i, item in enumerate(test[:10]):\n",
                "#     guess = llama3_2_local(item)\n",
                "#     truth = item.price\n",
                "#     error = abs(guess - truth)\n",
                "#     print(f\"{i+1}: Guess: ${guess:,.2f} | Truth: ${truth:,.2f} | Error: ${error:,.2f} | Item: {item.title[:40]}...\")\n",
                "#     time.sleep(1)\n",
                "\n",
                "# Full test set\n",
                "print(\"Running Tester on llama3.2 with the full test set\")\n",
                "Tester.test(llama3_2_local, test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fe1a3464",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3d0e900a",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a24692b6",
            "metadata": {},
            "source": [
                "#### <code>**day5.ipynb**</code>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3d17b2f2",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "<b style=\"font-size: 16px;\">Abstract:</b> Fine-tune the <b>GPT-4o-mini</b> model using OpenAI's API. Prepare the dataset in <code>JSONL</code> format, upload to OpenAI, initiate fine-tuning, and evaluate the accuracy of the customized Product Pricer model.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99a96cf0",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h4 style=\"margin-bottom: 0.2em; font-size: 18px;\"><b>The Product Pricer Continued</b></h4>\n",
                "  A model that can estimate how much something costs, from its description.\n",
                "</div>\n",
                "\n",
                "<br style=\"margin: 0; padding: 0;\">\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>AT LAST – it’s time for Fine Tuning!</b></h5>\n",
                "  After all this data preparation and old-school machine learning, we’ve finally arrived at the moment you’ve been waiting for: fine-tuning a model.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "82b7f78a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import math\n",
                "import json\n",
                "import random\n",
                "from dotenv import load_dotenv\n",
                "from huggingface_hub import login\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pickle\n",
                "from collections import Counter\n",
                "from openai import OpenAI\n",
                "from anthropic import Anthropic\n",
                "import ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "df273e22",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv(override=True)\n",
                "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
                "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f2dcab46",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log in to HuggingFace\n",
                "\n",
                "hf_token = os.environ['HF_TOKEN']\n",
                "login(hf_token, add_to_git_credential=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "71f0b4d6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# moved our Tester into a separate package\n",
                "# call it with Tester.test(function_name, test_dataset)\n",
                "\n",
                "from items import Item\n",
                "from testing import Tester"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d45643b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "openai = OpenAI()\n",
                "# claude = Anthropic()\n",
                "llama_client = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8c5bcbb0",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('train.pkl', 'rb') as file:\n",
                "    train = pickle.load(file)\n",
                "\n",
                "with open('test.pkl', 'rb') as file:\n",
                "    test = pickle.load(file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e9f46a51",
            "metadata": {},
            "outputs": [],
            "source": [
                "# OpenAI recommends fine-tuning with populations of 50-100 examples\n",
                "# But as our examples are very small, I'm suggesting we go with 200 examples (and 1 epoch)\n",
                "\n",
                "fine_tune_train = train[:200]\n",
                "fine_tune_validation = train[200:250]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d50bbe3",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c38431fe",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Step 1</b></h5>\n",
                "  Prepare our data for fine-tuning in <code>JSONL</code> (JSON Lines) format and upload to OpenAI.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93970cbd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# First let's work on a good prompt for a Frontier model\n",
                "# Notice that I'm removing the \" to the nearest dollar\"\n",
                "# When we train our own models, we'll need to make the problem as easy as possible, \n",
                "# but a Frontier model needs no such simplification.\n",
                "\n",
                "def messages_for(item):\n",
                "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
                "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
                "    return [\n",
                "        {\"role\": \"system\", \"content\": system_message},\n",
                "        {\"role\": \"user\", \"content\": user_prompt},\n",
                "        {\"role\": \"assistant\", \"content\": f\"Price is ${item.price:.2f}\"}\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12577979",
            "metadata": {},
            "outputs": [],
            "source": [
                "messages_for(train[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8f61b566",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the items into a list of json objects - a \"jsonl\" string\n",
                "# Each row represents a message in the form:\n",
                "# {\"messages\" : [{\"role\": \"system\", \"content\": \"You estimate prices...\n",
                "\n",
                "\n",
                "def make_jsonl(items):\n",
                "    result = \"\"\n",
                "    for item in items:\n",
                "        messages = messages_for(item)\n",
                "        messages_str = json.dumps(messages)\n",
                "        result += '{\"messages\": ' + messages_str +'}\\n'\n",
                "    return result.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1dc01c9c",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(make_jsonl(train[:3]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ef73c9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the items into jsonl and write them to a file\n",
                "\n",
                "def write_jsonl(items, filename):\n",
                "    with open(filename, \"w\") as f:\n",
                "        jsonl = make_jsonl(items)\n",
                "        f.write(jsonl)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5e62af2",
            "metadata": {},
            "outputs": [],
            "source": [
                "write_jsonl(fine_tune_train, \"fine_tune_train.jsonl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "13c0212a",
            "metadata": {},
            "outputs": [],
            "source": [
                "write_jsonl(fine_tune_validation, \"fine_tune_validation.jsonl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "60d4c1fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(\"fine_tune_train.jsonl\", \"rb\") as f:\n",
                "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f338390d",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8f6c3707",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(\"fine_tune_validation.jsonl\", \"rb\") as f:\n",
                "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f02162b8",
            "metadata": {},
            "outputs": [],
            "source": [
                "validation_file"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8f639374",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f7fe4a94",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Step 2</b></h5>\n",
                "  I love <b>Weights and Biases</b> – a beautiful, free platform for monitoring training runs.  \n",
                "  Weights and Biases is integrated with OpenAI for fine-tuning.<br><br>\n",
                "  First set up your Weights & Biases free account at:<br>\n",
                "  <a href=\"https://wandb.ai\" target=\"_blank\">https://wandb.ai</a><br>\n",
                "  From the Avatar → <b>Settings</b> menu, near the bottom, you can create an API key.<br>\n",
                "  Then visit the OpenAI dashboard at:<br>\n",
                "  <a href=\"https://platform.openai.com/account/organization\" target=\"_blank\">https://platform.openai.com/account/organization</a><br>\n",
                "  In the <b>Integrations</b> section, you can add your Weights & Biases key.\n",
                "</div>\n",
                "\n",
                "<br>\n",
                "\n",
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>And now — time to Fine-tune!</b></h5>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "31095643",
            "metadata": {},
            "outputs": [],
            "source": [
                "wandb_integration = {\"type\": \"wandb\", \"wandb\": {\"project\": \"gpt-pricer\"}}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "093d7f88",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_file.id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "82aad8ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "openai.fine_tuning.jobs.create(\n",
                "    training_file=train_file.id,\n",
                "    validation_file=validation_file.id,\n",
                "    model=\"gpt-4o-mini-2024-07-18\",\n",
                "    seed=42,\n",
                "    hyperparameters={\"n_epochs\": 1},\n",
                "    integrations = [wandb_integration],\n",
                "    suffix=\"pricer\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "209b0a2e",
            "metadata": {},
            "outputs": [],
            "source": [
                "openai.fine_tuning.jobs.list(limit=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "10fec37c",
            "metadata": {},
            "outputs": [],
            "source": [
                "job_id = openai.fine_tuning.jobs.list(limit=1).data[0].id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "02c972f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "job_id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ba53304a",
            "metadata": {},
            "outputs": [],
            "source": [
                "openai.fine_tuning.jobs.retrieve(job_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a9ddbdd",
            "metadata": {},
            "outputs": [],
            "source": [
                "openai.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10).data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1262190",
            "metadata": {},
            "source": [
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20fec894",
            "metadata": {},
            "source": [
                "<div style=\"font-size: 14px; line-height: 1.5; margin: 0; padding: 0;\">\n",
                "  <h5 style=\"margin-bottom: 0.2em; font-size: 16px;\"><b>Step 3</b></h5>\n",
                "  Test our fine-tuned model\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33c377a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "fine_tuned_model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e9c201d9",
            "metadata": {},
            "outputs": [],
            "source": [
                "fine_tuned_model_name"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "16ae2823",
            "metadata": {},
            "outputs": [],
            "source": [
                "# The prompt\n",
                "\n",
                "def messages_for(item):\n",
                "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
                "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
                "    return [\n",
                "        {\"role\": \"system\", \"content\": system_message},\n",
                "        {\"role\": \"user\", \"content\": user_prompt},\n",
                "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5daab56",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try this out\n",
                "\n",
                "messages_for(test[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd7df1d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# A utility function to extract the price from a string\n",
                "\n",
                "def get_price(s):\n",
                "    s = s.replace('$','').replace(',','')\n",
                "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
                "    return float(match.group()) if match else 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aaeb8867",
            "metadata": {},
            "outputs": [],
            "source": [
                "get_price(\"The price is roughly $99.99 because blah blah\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b7f23b1a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# The function for gpt-4o-mini\n",
                "\n",
                "def gpt_fine_tuned(item):\n",
                "    response = openai.chat.completions.create(\n",
                "        model=fine_tuned_model_name, \n",
                "        messages=messages_for(item),\n",
                "        seed=42,\n",
                "        max_tokens=7\n",
                "    )\n",
                "    reply = response.choices[0].message.content\n",
                "    return get_price(reply)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0c438719",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(test[0].price)\n",
                "\n",
                "# Ensure fine_tuned_model_name is set\n",
                "print(\"Fine-tuned model name:\", fine_tuned_model_name)\n",
                "if not fine_tuned_model_name:\n",
                "\t# Retrieve the fine-tuned model name if not set\n",
                "\tfine_tuned_model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model\n",
                "\n",
                "if not fine_tuned_model_name:\n",
                "\traise ValueError(\"fine_tuned_model_name is not set. Please check your fine-tuning job.\")\n",
                "\n",
                "print(gpt_fine_tuned(test[0]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "07ed94e2",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(test[0].test_prompt())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a43c9b5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tester.test(gpt_fine_tuned, test)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llms-gpu",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
